[2025-12-22T10:53:55.819+0000] {processor.py:157} INFO - Started process (PID=681) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:53:55.833+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:53:55.837+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:53:55.836+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:53:56.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:54:03.539+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:54:03.538+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:54:04.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 8.705 seconds
[2025-12-22T10:54:38.285+0000] {processor.py:157} INFO - Started process (PID=688) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:54:38.299+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:54:38.317+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:54:38.316+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:54:39.263+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:54:46.767+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:54:46.766+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:54:52.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 14.460 seconds
[2025-12-22T10:55:26.495+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:55:26.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:55:26.543+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:55:26.511+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:55:27.785+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:55:36.868+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:55:36.868+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:55:42.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 16.307 seconds
[2025-12-22T10:56:15.193+0000] {processor.py:157} INFO - Started process (PID=707) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:56:15.215+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:56:15.242+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:56:15.242+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:56:16.433+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:56:22.762+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:56:22.761+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:56:24.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 9.567 seconds
[2025-12-22T10:56:55.802+0000] {processor.py:157} INFO - Started process (PID=714) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:56:55.803+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:56:55.818+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:56:55.807+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:56:56.279+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:57:01.535+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:57:01.535+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:57:03.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 7.761 seconds
[2025-12-22T10:57:36.737+0000] {processor.py:157} INFO - Started process (PID=723) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:57:37.675+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:57:37.717+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:57:37.716+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:57:38.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:57:40.105+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:57:40.104+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:57:41.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.431 seconds
[2025-12-22T10:58:13.349+0000] {processor.py:157} INFO - Started process (PID=728) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:58:13.396+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:58:13.415+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:58:13.410+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:58:15.301+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:58:20.344+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:58:20.343+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:58:23.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 10.695 seconds
[2025-12-22T10:58:56.283+0000] {processor.py:157} INFO - Started process (PID=734) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:58:56.304+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:58:56.312+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:58:56.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:58:57.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:59:05.304+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:59:05.304+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:59:08.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 12.774 seconds
[2025-12-22T10:59:40.795+0000] {processor.py:157} INFO - Started process (PID=740) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:59:40.802+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T10:59:40.805+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:59:40.804+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:59:41.414+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T10:59:45.355+0000] {logging_mixin.py:151} INFO - [2025-12-22T10:59:45.355+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T10:59:46.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.724 seconds
[2025-12-22T11:02:28.998+0000] {processor.py:157} INFO - Started process (PID=747) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:02:29.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:02:29.218+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:02:29.097+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:02:33.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:02:42.764+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:02:42.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:02:46.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 17.679 seconds
[2025-12-22T11:03:19.427+0000] {processor.py:157} INFO - Started process (PID=753) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:03:19.457+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:03:19.475+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:03:19.474+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:03:21.513+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:03:25.926+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:03:25.926+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:03:29.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 10.416 seconds
[2025-12-22T11:04:01.455+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:04:01.480+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:04:01.808+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:04:01.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:04:08.632+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:04:15.208+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:04:15.207+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:05:21.399+0000] {processor.py:157} INFO - Started process (PID=763) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:05:21.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:05:21.568+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:05:21.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:05:22.746+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:05:24.753+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:05:24.752+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:05:26.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.205 seconds
[2025-12-22T11:05:57.477+0000] {processor.py:157} INFO - Started process (PID=769) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:05:57.543+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:05:57.559+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:05:57.556+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:05:58.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:06:01.466+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:06:01.465+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:06:08.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.565 seconds
[2025-12-22T11:06:40.745+0000] {processor.py:157} INFO - Started process (PID=775) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:06:40.766+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:06:40.802+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:06:40.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:06:41.956+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:06:44.642+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:06:44.641+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:06:46.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.501 seconds
[2025-12-22T11:07:18.261+0000] {processor.py:157} INFO - Started process (PID=781) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:07:18.292+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:07:18.303+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:07:18.302+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:07:18.759+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:07:24.669+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:07:24.656+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:07:29.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.223 seconds
[2025-12-22T11:08:10.308+0000] {processor.py:157} INFO - Started process (PID=801) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:10.339+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:08:10.369+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:08:10.368+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:11.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:12.426+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:08:12.425+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:08:13.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.295 seconds
[2025-12-22T11:08:44.897+0000] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:44.905+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:08:44.911+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:08:44.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:45.309+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:08:47.088+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:08:47.088+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:08:48.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.143 seconds
[2025-12-22T11:09:19.143+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:19.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:09:19.195+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:09:19.194+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:20.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:21.897+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:09:21.896+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:09:22.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.825 seconds
[2025-12-22T11:09:53.974+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:53.976+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:09:54.007+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:09:54.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:54.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:09:58.303+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:09:58.302+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:09:59.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.908 seconds
[2025-12-22T11:10:31.175+0000] {processor.py:157} INFO - Started process (PID=824) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:10:31.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:10:31.210+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:10:31.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:10:32.461+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:10:35.444+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:10:35.443+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:10:37.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.073 seconds
[2025-12-22T11:13:58.319+0000] {processor.py:157} INFO - Started process (PID=618) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:13:58.343+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:13:58.354+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:13:58.347+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:13:59.448+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:14:03.689+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:14:03.688+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:14:06.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 8.462 seconds
[2025-12-22T11:14:38.297+0000] {processor.py:157} INFO - Started process (PID=635) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:14:38.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:14:38.340+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:14:38.335+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:14:39.503+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:14:41.196+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:14:41.186+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:14:42.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.222 seconds
[2025-12-22T11:15:13.781+0000] {processor.py:157} INFO - Started process (PID=650) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:13.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:15:13.837+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:15:13.837+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:14.125+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:15.748+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:15:15.748+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:15:16.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.714 seconds
[2025-12-22T11:15:47.411+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:47.423+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:15:47.428+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:15:47.427+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:48.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:15:49.481+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:15:49.481+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:15:53.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.657 seconds
[2025-12-22T11:16:23.647+0000] {processor.py:157} INFO - Started process (PID=677) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:16:23.662+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:16:23.697+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:16:23.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:16:24.384+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:16:28.813+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:16:28.812+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:16:29.455+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:16:29.455+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:16:30.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 7.016 seconds
[2025-12-22T11:17:02.287+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:02.314+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:17:02.326+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:02.325+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:03.949+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:09.967+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:09.966+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:17:11.248+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:11.248+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:17:12.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 10.407 seconds
[2025-12-22T11:17:44.627+0000] {processor.py:157} INFO - Started process (PID=691) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:44.655+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:17:44.660+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:44.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:45.600+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:17:48.916+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:48.916+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:17:50.287+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:17:50.287+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:17:51.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.541 seconds
[2025-12-22T11:18:22.092+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:22.095+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:18:22.099+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:22.098+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:22.248+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:22.934+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:22.934+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:18:23.206+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:23.201+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:18:23.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.345 seconds
[2025-12-22T11:18:54.640+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:54.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:18:54.655+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:54.653+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:54.927+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:18:57.175+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:57.175+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:18:57.358+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:18:57.357+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:18:57.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.985 seconds
[2025-12-22T11:19:28.294+0000] {processor.py:157} INFO - Started process (PID=707) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:19:28.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:19:28.316+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:19:28.314+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:19:28.468+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:19:29.174+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:19:29.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:19:29.534+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:19:29.534+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:19:29.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.627 seconds
[2025-12-22T11:20:02.121+0000] {processor.py:157} INFO - Started process (PID=712) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:02.135+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:20:02.153+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:02.152+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:02.951+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:06.415+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:06.414+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:20:07.457+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:07.457+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:20:07.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.826 seconds
[2025-12-22T11:20:39.209+0000] {processor.py:157} INFO - Started process (PID=717) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:39.211+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:20:39.214+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:39.213+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:39.328+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:20:40.077+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:40.076+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:20:41.105+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:20:41.104+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:20:41.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.159 seconds
[2025-12-22T11:22:07.955+0000] {processor.py:157} INFO - Started process (PID=724) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:22:08.489+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:22:08.555+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:22:08.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:22:10.920+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:22:28.373+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:22:28.363+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:22:30.512+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:22:30.511+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:22:33.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 28.059 seconds
[2025-12-22T11:24:16.141+0000] {processor.py:157} INFO - Started process (PID=618) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:16.178+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:24:16.208+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:16.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:16.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:17.109+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:17.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:24:17.354+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:17.354+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:24:17.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.467 seconds
[2025-12-22T11:24:49.458+0000] {processor.py:157} INFO - Started process (PID=625) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:49.460+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:24:49.473+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:49.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:49.652+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:24:50.197+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:50.197+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:24:50.858+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:24:50.858+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:24:51.235+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.801 seconds
[2025-12-22T11:25:22.582+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:25:22.584+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:25:22.598+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:25:22.596+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:25:23.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:25:25.538+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:25:25.538+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:25:26.912+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:25:26.912+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:25:27.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.388 seconds
[2025-12-22T11:25:58.713+0000] {processor.py:157} INFO - Started process (PID=649) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:25:58.722+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:25:58.739+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:25:58.738+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:25:59.222+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:26:00.683+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:26:00.682+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:26:01.544+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:26:01.544+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:26:02.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.456 seconds
[2025-12-22T11:26:35.676+0000] {processor.py:157} INFO - Started process (PID=655) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:26:35.716+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:26:35.855+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:26:35.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:26:37.471+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:26:39.009+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:26:39.009+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:26:39.554+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:26:39.554+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:26:40.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.788 seconds
[2025-12-22T11:27:13.185+0000] {processor.py:157} INFO - Started process (PID=660) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:13.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:27:13.216+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:13.215+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:15.846+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:20.418+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:20.418+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:27:22.337+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:22.337+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:27:24.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.180 seconds
[2025-12-22T11:27:54.925+0000] {processor.py:157} INFO - Started process (PID=665) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:54.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:27:54.929+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:54.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:55.012+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:27:55.432+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:55.431+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:27:55.681+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:27:55.653+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:27:55.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.925 seconds
[2025-12-22T11:28:27.164+0000] {processor.py:157} INFO - Started process (PID=670) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:27.188+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:28:27.193+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:27.192+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:27.339+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:27.950+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:27.949+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:28:28.401+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:28.401+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:28:28.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.463 seconds
[2025-12-22T11:28:58.935+0000] {processor.py:157} INFO - Started process (PID=675) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:58.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:28:58.940+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:58.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:59.016+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:28:59.328+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:59.327+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:28:59.422+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:28:59.421+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:28:59.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.629 seconds
[2025-12-22T11:29:30.010+0000] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:29:30.012+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:29:30.015+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:29:30.014+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:29:30.161+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:29:32.299+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:29:32.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:29:33.321+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:29:33.321+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:00:00+00:00, run_after=2025-12-22T11:30:00+00:00
[2025-12-22T11:29:34.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.618 seconds
[2025-12-22T11:30:05.125+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:05.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:30:05.130+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:30:05.130+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:05.206+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:06.248+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:30:06.246+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:30:06.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.489 seconds
[2025-12-22T11:30:37.326+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:37.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:30:37.333+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:30:37.332+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:37.580+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:30:37.852+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:30:37.852+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:30:38.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.916 seconds
[2025-12-22T11:31:09.548+0000] {processor.py:157} INFO - Started process (PID=717) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:10.169+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:31:10.203+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:31:10.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:10.474+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:13.935+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:31:13.934+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:31:14.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.700 seconds
[2025-12-22T11:31:44.790+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:44.810+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:31:44.813+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:31:44.812+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:45.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:31:46.124+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:31:46.123+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:31:47.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.326 seconds
[2025-12-22T11:32:59.262+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:32:59.275+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:32:59.279+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:32:59.278+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:32:59.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:33:03.196+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:33:03.195+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:33:05.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.520 seconds
[2025-12-22T11:33:37.033+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:33:37.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:33:37.079+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:33:37.072+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:33:37.407+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:33:38.247+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:33:38.246+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:33:39.650+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:33:39.649+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:33:40.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.144 seconds
[2025-12-22T11:34:10.598+0000] {processor.py:157} INFO - Started process (PID=650) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:10.602+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:34:10.614+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:10.614+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:10.735+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:12.031+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:12.031+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:34:12.484+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:12.484+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:34:13.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.662 seconds
[2025-12-22T11:34:44.563+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:44.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:34:44.596+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:44.595+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:45.646+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:34:46.450+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:46.450+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:34:47.094+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:34:47.093+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:34:47.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.011 seconds
[2025-12-22T11:35:18.027+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:18.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:35:18.040+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:18.039+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:18.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:18.778+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:18.777+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:35:19.057+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:19.056+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:35:19.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.215 seconds
[2025-12-22T11:35:49.813+0000] {processor.py:157} INFO - Started process (PID=675) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:49.815+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:35:49.879+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:49.817+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:50.367+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:35:50.915+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:50.913+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:35:51.388+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:35:51.388+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:35:51.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.775 seconds
[2025-12-22T11:36:22.330+0000] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:22.332+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:36:22.335+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:22.334+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:22.402+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:23.262+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:23.262+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:36:23.429+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:23.428+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:36:24.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.882 seconds
[2025-12-22T11:36:55.425+0000] {processor.py:157} INFO - Started process (PID=685) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:55.427+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:36:55.429+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:55.429+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:55.694+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:36:56.668+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:56.668+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:36:56.746+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:36:56.746+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:36:56.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.464 seconds
[2025-12-22T11:37:28.175+0000] {processor.py:157} INFO - Started process (PID=690) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:37:28.177+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:37:28.180+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:37:28.180+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:37:28.404+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:37:29.901+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:37:29.901+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:37:29.974+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:37:29.974+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:37:30.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.446 seconds
[2025-12-22T11:38:02.343+0000] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:02.345+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:38:02.346+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:02.346+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:02.476+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:03.759+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:03.759+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:38:03.872+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:03.871+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:38:04.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.226 seconds
[2025-12-22T11:38:35.630+0000] {processor.py:157} INFO - Started process (PID=700) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:35.632+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:38:35.635+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:35.634+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:35.793+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:38:38.122+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:38.111+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:38:38.940+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:38:38.939+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:38:39.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.116 seconds
[2025-12-22T11:39:10.290+0000] {processor.py:157} INFO - Started process (PID=705) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:10.298+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:39:10.307+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:10.306+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:11.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:12.599+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:12.589+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:39:14.765+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:14.762+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:39:14.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.655 seconds
[2025-12-22T11:39:45.773+0000] {processor.py:157} INFO - Started process (PID=710) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:45.817+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:39:45.856+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:45.855+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:46.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:39:46.290+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:46.290+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:39:46.358+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:39:46.358+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:39:46.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.670 seconds
[2025-12-22T11:40:17.314+0000] {processor.py:157} INFO - Started process (PID=715) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:17.316+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:40:17.321+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:40:17.320+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:17.545+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:18.427+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:40:18.426+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:40:19.865+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:40:19.854+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:40:20.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.827 seconds
[2025-12-22T11:40:50.485+0000] {processor.py:157} INFO - Started process (PID=721) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:50.487+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:40:50.498+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:40:50.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:51.324+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:40:52.167+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:40:52.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:40:52.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.953 seconds
[2025-12-22T11:41:23.894+0000] {processor.py:157} INFO - Started process (PID=743) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:23.899+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:41:23.910+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:41:23.909+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:24.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:25.283+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:41:25.276+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:41:25.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.790 seconds
[2025-12-22T11:41:56.488+0000] {processor.py:157} INFO - Started process (PID=754) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:56.490+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:41:56.493+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:41:56.492+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:56.631+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:41:57.316+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:41:57.316+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:41:58.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.857 seconds
[2025-12-22T11:42:29.307+0000] {processor.py:157} INFO - Started process (PID=776) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:42:29.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:42:29.314+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:42:29.312+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:42:29.400+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:42:29.824+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:42:29.824+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:42:30.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.745 seconds
[2025-12-22T11:43:01.177+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:01.182+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:43:01.201+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:01.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:02.079+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:04.831+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:04.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:43:05.467+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:05.456+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:43:05.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.689 seconds
[2025-12-22T11:43:36.529+0000] {processor.py:157} INFO - Started process (PID=794) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:36.530+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:43:36.534+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:36.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:36.590+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:43:37.043+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:37.042+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:43:37.197+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:43:37.197+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:43:37.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.781 seconds
[2025-12-22T11:44:07.448+0000] {processor.py:157} INFO - Started process (PID=799) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:07.450+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:44:07.453+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:07.453+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:07.609+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:08.044+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:08.044+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:44:08.295+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:08.295+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:44:08.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.051 seconds
[2025-12-22T11:44:39.405+0000] {processor.py:157} INFO - Started process (PID=804) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:39.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:44:39.409+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:39.409+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:39.552+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:44:40.209+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:40.208+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:44:40.371+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:44:40.371+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:44:40.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.097 seconds
[2025-12-22T11:45:11.830+0000] {processor.py:157} INFO - Started process (PID=809) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:11.836+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:45:11.847+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:11.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:12.043+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:13.585+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:13.584+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:45:13.876+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:13.875+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:45:14.292+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.501 seconds
[2025-12-22T11:45:44.684+0000] {processor.py:157} INFO - Started process (PID=814) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:44.697+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:45:44.703+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:44.702+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:44.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:45:45.355+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:45.355+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:45:45.936+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:45:45.936+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:45:46.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.528 seconds
[2025-12-22T11:46:16.579+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:16.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:46:16.582+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:16.582+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:16.730+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:17.702+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:17.701+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:46:17.980+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:17.980+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:46:18.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.547 seconds
[2025-12-22T11:46:48.529+0000] {processor.py:157} INFO - Started process (PID=824) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:48.531+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:46:48.533+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:48.532+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:48.608+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:46:48.963+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:48.953+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:46:49.136+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:46:49.135+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:46:49.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.719 seconds
[2025-12-22T11:47:19.415+0000] {processor.py:157} INFO - Started process (PID=829) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:19.417+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:47:19.418+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:19.418+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:19.466+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:19.718+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:19.718+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:47:19.784+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:19.784+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:47:20.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.827 seconds
[2025-12-22T11:47:51.053+0000] {processor.py:157} INFO - Started process (PID=834) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:51.072+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:47:51.091+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:51.088+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:51.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:47:51.767+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:51.766+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:47:51.952+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:47:51.951+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:47:52.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.031 seconds
[2025-12-22T11:48:22.940+0000] {processor.py:157} INFO - Started process (PID=840) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:22.943+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:48:22.953+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:22.945+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:23.096+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:24.147+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:24.146+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:48:24.389+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:24.388+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:48:24.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.652 seconds
[2025-12-22T11:48:55.157+0000] {processor.py:157} INFO - Started process (PID=845) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:55.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:48:55.188+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:55.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:55.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:48:56.183+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:56.182+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:48:56.410+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:48:56.409+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:48:56.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.456 seconds
[2025-12-22T11:49:27.592+0000] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:49:27.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:49:27.599+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:49:27.598+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:49:27.962+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:49:29.108+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:49:29.107+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:49:29.599+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:49:29.598+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:49:30.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.742 seconds
[2025-12-22T11:50:02.880+0000] {processor.py:157} INFO - Started process (PID=857) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:02.888+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:50:02.891+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:02.890+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:03.154+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:06.153+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:06.152+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:50:06.615+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:06.614+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:50:07.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.671 seconds
[2025-12-22T11:50:38.889+0000] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:38.890+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:50:38.899+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:38.892+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:39.039+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:50:41.271+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:41.270+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:50:42.262+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:50:42.261+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T11:30:00+00:00, run_after=2025-12-22T12:00:00+00:00
[2025-12-22T11:50:42.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.632 seconds
[2025-12-22T11:51:17.681+0000] {processor.py:157} INFO - Started process (PID=868) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:51:17.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:51:17.781+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:51:17.777+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:51:20.113+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:51:32.465+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:51:32.462+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:51:34.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 17.520 seconds
[2025-12-22T11:52:05.170+0000] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:05.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:52:05.202+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:52:05.184+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:05.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:07.751+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:52:07.750+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:52:08.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.773 seconds
[2025-12-22T11:52:40.974+0000] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:40.977+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:52:41.006+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:52:40.993+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:42.292+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:52:45.066+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:52:44.920+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:52:45.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.714 seconds
[2025-12-22T11:53:16.641+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:53:16.642+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:53:16.656+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:53:16.645+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:53:16.851+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:53:22.712+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:53:22.661+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:53:23.204+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.600 seconds
[2025-12-22T11:53:54.171+0000] {processor.py:157} INFO - Started process (PID=899) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:53:54.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:53:54.193+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:53:54.176+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:53:54.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:54:05.035+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:54:04.972+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:54:05.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.875 seconds
[2025-12-22T11:54:36.758+0000] {processor.py:157} INFO - Started process (PID=905) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:54:36.762+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:54:36.765+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:54:36.764+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:54:37.144+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:54:38.417+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:54:38.379+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:54:38.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.054 seconds
[2025-12-22T11:55:10.960+0000] {processor.py:157} INFO - Started process (PID=918) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:10.992+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:55:11.055+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:55:10.995+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:11.625+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:13.566+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:55:13.565+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:55:15.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.243 seconds
[2025-12-22T11:55:46.064+0000] {processor.py:157} INFO - Started process (PID=925) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:46.065+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:55:46.068+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:55:46.068+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:46.170+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:55:47.650+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:55:47.650+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:55:47.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.881 seconds
[2025-12-22T11:56:20.273+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:56:20.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:56:20.318+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:56:20.297+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:56:21.925+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:56:26.458+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:56:26.457+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:56:27.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.780 seconds
[2025-12-22T11:56:57.943+0000] {processor.py:157} INFO - Started process (PID=937) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:56:57.946+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:56:57.949+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:56:57.948+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:56:58.273+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:57:00.565+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:57:00.564+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:57:01.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.184 seconds
[2025-12-22T11:59:19.863+0000] {processor.py:157} INFO - Started process (PID=621) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:19.877+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:59:19.885+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:59:19.884+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:20.087+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:23.199+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:59:23.198+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:59:24.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.312 seconds
[2025-12-22T11:59:54.929+0000] {processor.py:157} INFO - Started process (PID=627) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:54.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T11:59:54.944+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:59:54.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:55.275+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T11:59:56.127+0000] {logging_mixin.py:151} INFO - [2025-12-22T11:59:56.127+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T11:59:58.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.694 seconds
[2025-12-22T12:00:29.000+0000] {processor.py:157} INFO - Started process (PID=654) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:00:29.013+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:00:29.023+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:00:29.017+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:00:29.287+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:00:29.718+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:00:29.718+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:00:30.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.363 seconds
[2025-12-22T12:01:01.123+0000] {processor.py:157} INFO - Started process (PID=679) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:01.125+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:01:01.127+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:01:01.127+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:01.563+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:02.785+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:01:02.784+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:01:04.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.031 seconds
[2025-12-22T12:01:35.268+0000] {processor.py:157} INFO - Started process (PID=705) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:35.270+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:01:35.285+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:01:35.274+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:35.441+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:01:36.301+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:01:36.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:01:36.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.632 seconds
[2025-12-22T12:02:07.946+0000] {processor.py:157} INFO - Started process (PID=718) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:08.025+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:02:08.047+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:02:08.046+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:08.425+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:09.619+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:02:09.618+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:02:10.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.498 seconds
[2025-12-22T12:02:41.257+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:41.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:02:41.268+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:02:41.261+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:42.037+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:02:45.960+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:02:45.959+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:02:46.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.656 seconds
[2025-12-22T12:03:17.947+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:17.949+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:03:17.984+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:03:17.962+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:18.845+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:21.460+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:03:21.455+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:03:22.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.287 seconds
[2025-12-22T12:03:52.990+0000] {processor.py:157} INFO - Started process (PID=757) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:52.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:03:53.016+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:03:53.001+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:53.291+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:03:58.477+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:03:58.385+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:03:59.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.249 seconds
[2025-12-22T12:04:29.689+0000] {processor.py:157} INFO - Started process (PID=762) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:04:29.692+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:04:29.695+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:04:29.694+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:04:30.001+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:04:30.947+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:04:30.946+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:04:31.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.494 seconds
[2025-12-22T12:05:01.888+0000] {processor.py:157} INFO - Started process (PID=772) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:01.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:05:01.908+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:05:01.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:02.304+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:04.202+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:05:04.190+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:05:04.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.800 seconds
[2025-12-22T12:05:35.183+0000] {processor.py:157} INFO - Started process (PID=793) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:35.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:05:35.200+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:05:35.199+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:35.477+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:05:37.731+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:05:37.719+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:05:38.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.130 seconds
[2025-12-22T12:06:09.487+0000] {processor.py:157} INFO - Started process (PID=800) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:09.491+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:06:09.506+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:06:09.493+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:09.899+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:11.872+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:06:11.869+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:06:12.458+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.018 seconds
[2025-12-22T12:06:43.221+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:43.225+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:06:43.238+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:06:43.228+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:43.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:06:44.622+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:06:44.621+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:06:45.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.917 seconds
[2025-12-22T12:07:15.786+0000] {processor.py:157} INFO - Started process (PID=828) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:15.789+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:07:15.809+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:07:15.794+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:16.858+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:17.997+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:07:17.997+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:07:18.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.802 seconds
[2025-12-22T12:07:49.034+0000] {processor.py:157} INFO - Started process (PID=834) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:49.036+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:07:49.038+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:07:49.037+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:49.228+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:07:50.917+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:07:50.916+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:07:51.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.278 seconds
[2025-12-22T12:08:21.923+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:21.926+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:08:21.949+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:08:21.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:22.158+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:23.865+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:08:23.862+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:08:24.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.193 seconds
[2025-12-22T12:08:54.500+0000] {processor.py:157} INFO - Started process (PID=853) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:54.501+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:08:54.507+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:08:54.502+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:54.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:08:55.018+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:08:55.017+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:08:55.198+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:08:55.198+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:08:55.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.832 seconds
[2025-12-22T12:09:25.577+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:09:25.580+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:09:25.598+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:09:25.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:09:25.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:09:27.523+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:09:27.522+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:09:28.530+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:09:28.521+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:09:28.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.349 seconds
[2025-12-22T12:09:59.254+0000] {processor.py:157} INFO - Started process (PID=863) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:09:59.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:09:59.262+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:09:59.259+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:09:59.371+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:10:00.616+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:10:00.616+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:10:00.951+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:10:00.950+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:10:01.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.964 seconds
[2025-12-22T12:10:32.835+0000] {processor.py:157} INFO - Started process (PID=868) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:10:32.844+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:10:32.849+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:10:32.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:10:33.403+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:10:34.614+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:10:34.614+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:10:35.661+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:10:35.660+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:10:36.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.346 seconds
[2025-12-22T12:11:06.662+0000] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:06.663+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:11:06.680+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:11:06.679+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:06.758+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:07.137+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:11:07.136+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:11:07.336+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:11:07.335+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:11:07.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.827 seconds
[2025-12-22T12:11:38.481+0000] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:38.485+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:11:38.498+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:11:38.495+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:38.790+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:11:39.485+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:11:39.484+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:11:39.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.481 seconds
[2025-12-22T12:12:11.106+0000] {processor.py:157} INFO - Started process (PID=903) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:12:11.108+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:12:11.134+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:12:11.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:12:11.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:12:19.900+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:12:19.862+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:12:20.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 9.175 seconds
[2025-12-22T12:12:51.183+0000] {processor.py:157} INFO - Started process (PID=908) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:12:51.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:12:51.203+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:12:51.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:12:51.585+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:13:01.559+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:13:01.344+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:13:02.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.063 seconds
[2025-12-22T12:13:33.353+0000] {processor.py:157} INFO - Started process (PID=913) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:13:33.357+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:13:33.367+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:13:33.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:13:33.630+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:13:34.910+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:13:34.891+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:13:35.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.903 seconds
[2025-12-22T12:14:06.376+0000] {processor.py:157} INFO - Started process (PID=918) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:14:06.387+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:14:06.412+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:14:06.401+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:14:07.005+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:14:11.743+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:14:11.631+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:14:13.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 6.720 seconds
[2025-12-22T12:14:45.538+0000] {processor.py:157} INFO - Started process (PID=923) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:14:45.555+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:14:45.636+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:14:45.608+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:14:47.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:15:19.660+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:15:52.068+0000] {processor.py:157} INFO - Started process (PID=928) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:15:52.071+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:15:52.080+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:15:52.073+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:15:52.343+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:15:55.979+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:15:55.952+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:15:56.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.202 seconds
[2025-12-22T12:16:26.912+0000] {processor.py:157} INFO - Started process (PID=933) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:16:26.932+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:16:26.949+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:16:26.935+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:16:27.212+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:16:28.318+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:16:28.291+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:16:28.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.691 seconds
[2025-12-22T12:17:00.919+0000] {processor.py:157} INFO - Started process (PID=938) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:17:00.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:17:00.990+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:17:00.961+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:17:02.073+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:17:35.973+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:18:08.959+0000] {processor.py:157} INFO - Started process (PID=943) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:18:08.969+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:18:09.002+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:18:08.986+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:18:09.566+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:18:45.543+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:19:20.273+0000] {processor.py:157} INFO - Started process (PID=948) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:19:20.277+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:19:20.308+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:19:20.289+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:19:22.315+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:19:56.364+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:19:55.971+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:20:02.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 42.395 seconds
[2025-12-22T12:20:37.106+0000] {processor.py:157} INFO - Started process (PID=953) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:20:37.131+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:20:37.196+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:20:37.195+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:20:38.216+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:20:43.593+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:20:43.593+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:20:45.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 8.557 seconds
[2025-12-22T12:21:17.681+0000] {processor.py:157} INFO - Started process (PID=958) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:21:17.686+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:21:17.743+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:21:17.742+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:21:18.645+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:21:24.328+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:21:24.327+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:21:25.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 8.240 seconds
[2025-12-22T12:21:58.662+0000] {processor.py:157} INFO - Started process (PID=964) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:21:58.664+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:21:58.749+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:21:58.693+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:21:59.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:22:06.062+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:22:06.046+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:22:07.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 10.134 seconds
[2025-12-22T12:22:53.964+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:22:54.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:22:54.543+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:22:54.321+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:22:59.830+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:23:11.919+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:23:11.919+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:23:15.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 26.243 seconds
[2025-12-22T12:23:46.763+0000] {processor.py:157} INFO - Started process (PID=974) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:23:46.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:23:46.849+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:23:46.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:23:47.494+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:23:49.423+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:23:49.422+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:23:50.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.548 seconds
[2025-12-22T12:24:22.013+0000] {processor.py:157} INFO - Started process (PID=979) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:24:22.031+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:24:22.034+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:24:22.033+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:24:22.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:24:23.815+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:24:23.794+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:24:27.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.147 seconds
[2025-12-22T12:24:59.014+0000] {processor.py:157} INFO - Started process (PID=985) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:24:59.017+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:24:59.033+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:24:59.031+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:24:59.692+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:25:08.863+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:25:08.862+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:25:10.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.705 seconds
[2025-12-22T12:25:43.513+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:25:43.545+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:25:43.594+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:25:43.594+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:25:44.434+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:25:51.095+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:25:51.095+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:25:54.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 11.578 seconds
[2025-12-22T12:26:29.212+0000] {processor.py:157} INFO - Started process (PID=997) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:26:29.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:26:29.281+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:26:29.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:26:29.976+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:26:32.108+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:26:32.108+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:26:33.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.049 seconds
[2025-12-22T12:27:04.677+0000] {processor.py:157} INFO - Started process (PID=1004) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:04.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:27:04.729+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:27:04.728+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:05.340+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:07.921+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:27:07.921+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:27:08.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.003 seconds
[2025-12-22T12:27:40.106+0000] {processor.py:157} INFO - Started process (PID=1017) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:40.257+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:27:40.307+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:27:40.277+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:41.172+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:27:47.044+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:27:47.044+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:28:16.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 36.863 seconds
[2025-12-22T12:28:47.569+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:28:47.579+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:28:47.594+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:28:47.593+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:28:47.907+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:28:48.864+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:28:48.863+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:28:49.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.777 seconds
[2025-12-22T12:29:20.223+0000] {processor.py:157} INFO - Started process (PID=1045) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:20.227+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:29:20.231+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:20.230+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:20.408+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:21.076+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:21.074+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:29:21.451+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:21.450+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:29:21.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.405 seconds
[2025-12-22T12:29:52.259+0000] {processor.py:157} INFO - Started process (PID=1050) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:52.263+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:29:52.281+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:52.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:52.443+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:29:52.736+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:52.735+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:29:52.822+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:29:52.821+0000] {dag.py:3677} INFO - Setting next_dagrun for energy_complete_pipeline_orchestration to 2025-12-22T12:00:00+00:00, run_after=2025-12-22T12:30:00+00:00
[2025-12-22T12:29:52.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.658 seconds
[2025-12-22T12:30:23.400+0000] {processor.py:157} INFO - Started process (PID=1058) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:23.407+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:30:23.413+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:30:23.412+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:23.607+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:24.092+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:30:24.092+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:30:24.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.032 seconds
[2025-12-22T12:30:54.988+0000] {processor.py:157} INFO - Started process (PID=1084) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:54.990+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:30:55.004+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:30:55.003+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:55.103+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:30:55.932+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:30:55.932+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:30:56.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.356 seconds
[2025-12-22T12:31:27.235+0000] {processor.py:157} INFO - Started process (PID=1098) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:31:27.242+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:31:27.254+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:31:27.245+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:31:27.462+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:31:28.838+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:31:28.837+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:31:29.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.966 seconds
[2025-12-22T12:32:01.197+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:01.204+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:32:01.223+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:32:01.212+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:01.639+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:03.536+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:32:03.536+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:32:04.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.127 seconds
[2025-12-22T12:32:35.138+0000] {processor.py:157} INFO - Started process (PID=1127) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:35.155+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:32:35.172+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:32:35.157+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:35.352+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:32:35.824+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:32:35.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:32:36.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 0.928 seconds
[2025-12-22T12:33:09.492+0000] {processor.py:157} INFO - Started process (PID=1133) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:33:09.506+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:33:09.549+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:33:09.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:33:10.623+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:33:44.596+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:34:02.075+0000] {processor.py:157} INFO - Started process (PID=1138) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:02.077+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:34:02.090+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:02.080+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:02.422+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:04.426+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:04.403+0000] {taskinstance.py:1945} ERROR - {'DAG Id': 'energy_complete_pipeline_orchestration', 'Task Id': 'check_infrastructure', 'Run Id': 'manual__2025-12-22T12:31:43.665565+00:00', 'Hostname': '1fdfe70c11b0'}
[2025-12-22T12:34:04.551+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:04.551+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=energy_complete_pipeline_orchestration, task_id=check_infrastructure, execution_date=20251222T123143, start_date=20251222T123240, end_date=20251222T123404
[2025-12-22T12:34:04.636+0000] {processor.py:790} INFO - Executed failure callback for <TaskInstance: energy_complete_pipeline_orchestration.check_infrastructure manual__2025-12-22T12:31:43.665565+00:00 [up_for_retry]> in state up_for_retry
[2025-12-22T12:34:04.839+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:04.838+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:34:05.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.994 seconds
[2025-12-22T12:34:37.493+0000] {processor.py:157} INFO - Started process (PID=1144) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:37.553+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:34:37.666+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:37.573+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:37.969+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:34:40.361+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:34:40.360+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:34:41.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.561 seconds
[2025-12-22T12:35:13.901+0000] {processor.py:157} INFO - Started process (PID=1149) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:13.916+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:35:13.980+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:35:13.928+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:14.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:17.431+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:35:17.430+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:35:18.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.990 seconds
[2025-12-22T12:35:49.540+0000] {processor.py:157} INFO - Started process (PID=1154) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:49.544+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:35:49.556+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:35:49.547+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:49.931+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:35:51.591+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:35:51.591+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:35:54.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.099 seconds
[2025-12-22T12:36:26.157+0000] {processor.py:157} INFO - Started process (PID=1159) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:36:26.191+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:36:26.201+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:36:26.198+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:36:26.944+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:36:30.828+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:36:30.828+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:36:32.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 5.891 seconds
[2025-12-22T12:37:03.388+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:37:03.404+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:37:03.533+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:37:03.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:37:04.483+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:37:37.690+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:38:20.902+0000] {processor.py:157} INFO - Started process (PID=1170) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:20.904+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:38:20.915+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:38:20.906+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:21.168+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:22.941+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:38:22.930+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:38:23.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.445 seconds
[2025-12-22T12:38:55.167+0000] {processor.py:157} INFO - Started process (PID=1175) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:55.170+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:38:55.180+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:38:55.172+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:55.538+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:38:57.960+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:38:57.926+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:38:58.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.147 seconds
[2025-12-22T12:39:28.708+0000] {processor.py:157} INFO - Started process (PID=1180) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:39:28.710+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:39:28.725+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:39:28.712+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:39:28.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:39:29.853+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:39:29.853+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:39:30.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.502 seconds
[2025-12-22T12:40:00.870+0000] {processor.py:157} INFO - Started process (PID=1185) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:00.873+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:40:00.896+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:40:00.883+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:01.455+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:02.637+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:40:02.637+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:40:03.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.708 seconds
[2025-12-22T12:40:35.626+0000] {processor.py:157} INFO - Started process (PID=1190) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:35.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:40:35.690+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:40:35.637+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:36.175+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:40:52.344+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:40:52.156+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:40:52.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 17.366 seconds
[2025-12-22T12:41:24.969+0000] {processor.py:157} INFO - Started process (PID=1196) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:41:24.973+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:41:25.061+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:41:24.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:41:26.136+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:41:48.391+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:41:48.384+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:41:49.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 24.164 seconds
[2025-12-22T12:42:20.842+0000] {processor.py:157} INFO - Started process (PID=1203) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:42:20.846+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:42:20.870+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:42:20.857+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:42:21.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:42:25.219+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:42:25.196+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:42:25.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 4.770 seconds
[2025-12-22T12:43:03.655+0000] {processor.py:157} INFO - Started process (PID=1217) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:43:04.559+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:43:06.966+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:43:05.413+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:43:23.457+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:18.631+0000] {processor.py:157} INFO - Started process (PID=1229) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:18.634+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:45:18.665+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:45:18.662+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:19.179+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:21.031+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:45:21.030+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:45:21.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.727 seconds
[2025-12-22T12:45:52.252+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:52.265+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:45:52.307+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:45:52.269+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:52.786+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:45:59.804+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:45:59.784+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:46:00.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 8.221 seconds
[2025-12-22T12:46:37.272+0000] {processor.py:157} INFO - Started process (PID=1242) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:46:37.288+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:46:37.347+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:46:37.290+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:46:37.855+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:46:49.370+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:46:49.283+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:46:49.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 12.722 seconds
[2025-12-22T12:47:21.591+0000] {processor.py:157} INFO - Started process (PID=1249) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:47:21.596+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:47:21.640+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:47:21.635+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:47:23.018+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:47:28.831+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:47:28.830+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:47:29.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 7.593 seconds
[2025-12-22T12:48:00.416+0000] {processor.py:157} INFO - Started process (PID=1263) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:00.418+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:48:00.426+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:48:00.420+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:00.603+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:01.592+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:48:01.554+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:48:01.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.520 seconds
[2025-12-22T12:48:32.671+0000] {processor.py:157} INFO - Started process (PID=1268) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:32.672+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:48:32.691+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:48:32.674+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:32.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:48:35.195+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:48:35.177+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:48:35.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 2.975 seconds
[2025-12-22T12:49:06.752+0000] {processor.py:157} INFO - Started process (PID=1273) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:49:06.754+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:49:06.791+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:49:06.757+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:49:07.293+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:49:39.250+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:50:13.171+0000] {processor.py:157} INFO - Started process (PID=1278) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:13.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:50:13.181+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:50:13.175+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:13.341+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:16.097+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:50:16.074+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:50:16.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.387 seconds
[2025-12-22T12:50:47.178+0000] {processor.py:157} INFO - Started process (PID=1283) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:47.179+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:50:47.191+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:50:47.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:47.355+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:50:48.529+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:50:48.477+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:50:49.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.914 seconds
[2025-12-22T12:51:20.600+0000] {processor.py:157} INFO - Started process (PID=1288) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:51:20.603+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:51:20.621+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:51:20.609+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:51:20.935+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:51:22.269+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:51:22.252+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:51:22.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.969 seconds
[2025-12-22T12:51:53.475+0000] {processor.py:157} INFO - Started process (PID=1293) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:51:53.477+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:51:53.489+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:51:53.481+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:51:53.878+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:52:03.647+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:52:03.598+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:52:04.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 10.672 seconds
[2025-12-22T12:52:35.277+0000] {processor.py:157} INFO - Started process (PID=1298) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:52:35.278+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:52:35.290+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:52:35.280+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:52:35.533+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:52:38.229+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:52:38.205+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:52:38.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 3.330 seconds
[2025-12-22T12:53:09.109+0000] {processor.py:157} INFO - Started process (PID=1303) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:09.112+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:53:09.129+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:53:09.117+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:09.572+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:16.050+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:53:16.020+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:53:16.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 7.519 seconds
[2025-12-22T12:53:47.125+0000] {processor.py:157} INFO - Started process (PID=1308) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:47.127+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:53:47.134+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:53:47.129+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:47.276+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:53:48.439+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:53:48.425+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-12-22T12:53:48.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/energy_pipeline_orchestration.py took 1.649 seconds
[2025-12-22T12:54:20.050+0000] {processor.py:157} INFO - Started process (PID=1313) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:20.053+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:54:20.063+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:54:20.061+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:21.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:21.765+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:54:53.137+0000] {processor.py:157} INFO - Started process (PID=1318) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:53.140+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:54:53.142+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:54:53.141+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:53.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:54:53.678+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:55:24.061+0000] {processor.py:157} INFO - Started process (PID=1323) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:24.063+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:55:24.065+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:55:24.064+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:24.115+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:25.285+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:55:55.551+0000] {processor.py:157} INFO - Started process (PID=1328) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:55.552+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:55:55.555+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:55:55.554+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:55.617+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:55:56.323+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:56:27.299+0000] {processor.py:157} INFO - Started process (PID=1333) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:27.300+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:56:27.302+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:56:27.301+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:27.348+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:28.458+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:56:58.685+0000] {processor.py:157} INFO - Started process (PID=1338) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:58.688+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:56:58.690+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:56:58.689+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:58.801+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:56:59.699+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:57:30.083+0000] {processor.py:157} INFO - Started process (PID=1343) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:57:30.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:57:30.096+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:57:30.095+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:57:30.186+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:57:30.802+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:58:01.269+0000] {processor.py:157} INFO - Started process (PID=1348) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:01.271+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:58:01.275+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:58:01.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:01.351+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:02.451+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:58:32.904+0000] {processor.py:157} INFO - Started process (PID=1353) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:32.906+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:58:32.909+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:58:32.908+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:32.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:58:33.734+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:59:04.172+0000] {processor.py:157} INFO - Started process (PID=1358) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:04.173+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:59:04.175+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:59:04.174+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:04.218+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:05.376+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:59:09.775+0000] {processor.py:157} INFO - Started process (PID=1363) to work on /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:09.779+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/energy_pipeline_orchestration.py for tasks to queue
[2025-12-22T12:59:09.782+0000] {logging_mixin.py:151} INFO - [2025-12-22T12:59:09.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:09.853+0000] {processor.py:839} INFO - DAG(s) dict_keys(['energy_complete_pipeline_orchestration']) retrieved from /opt/airflow/dags/energy_pipeline_orchestration.py
[2025-12-22T12:59:09.862+0000] {processor.py:713} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/energy_pipeline_orchestration.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 707, in execute_callbacks
    self._execute_task_callbacks(dagbag, request, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 755, in _execute_task_callbacks
    session.query(TI)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-12-22T12:59:10.673+0000] {processor.py:182} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 178, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 159, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 857, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 112, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 893, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 669, in _sync_to_db
    serialize_errors.extend(_serialize_dag_capturing_errors(dag, session))
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 636, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 147, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 406, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
